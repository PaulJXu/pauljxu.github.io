---
layout: post
title: 如何处理不平衡数据集
subtitle: How to handle imbalanced datasets
header-style: text
author: jerpson
tags:
    - machine learning
---

在机器学习中常常会遇到非平衡的数据集，比如信用卡欺诈交易检测、产品质量检测等场景。在这些应用场景中，一般稀有类的正确分类比多数类的正确分类更有价值。

首先，我们需要确认手中的的非平衡样本与真实需要预测的情况是否一致。因为，机器学习的前提是训练集与预测的数据（或者说是测试集）的分布是一致的。如果真实情况不是这种非平衡，则需要考虑重新收集数据。

在确认数据是非平衡后，我们可以考虑从以下几个方面处理。

## 选择合适的评估指标

由于准确率(accuracy)将每类看得同等重要，因此它不适合用来评估非平衡数据集。以二分类为例，通常我们将稀有类记为正类。在模型建立后我们可以获得混淆矩阵和相关的度量。此时我们可以使用精度（precision）和召回（recall）这两个指标去度量模型。最理想的情况是这两个指标都高，但两者是此消彼长的。因此，我们需要根据实际的应用场景去找到合适的度量。一般情况下你可以使用F1（精度和召回率的调和均值）。在某些场景下，我们更加注重精度，比如在贷中环节，由于前期有大量的获客及审核成本，如果此时模型精度过低，会导致大量客户的被拒；而如果是在贷前环节，我们可以使用更高召回率的模型，即抓到更多的欺诈用户。此时可以通过业务权衡设置一个合适的$$F_\beta$$。
$$
F_\beta = \frac{(\beta^2+1)*r*p}{r+\beta^2*p} \\
当 \beta=1时，F_\beta = F_1
$$

## 基于采样的方法

一般可以使用随机下采样（undersampling）和上采样（oversampling），或者两者的结合。

通过随机下采样可以建立多个分类器，然后通过集成学习的方式构建模型。

过采样没有向训练集中添加任何新的信息，对正样本的复制仅仅阻止算法剪掉模型中描述包含很少训练样本的区域的那部分。

![1557304486972](/img/in-post/1557304486972.png)

还有一种被常提及的smote方法，可以认为是过采样的变种。该方法不是简单的复制正样本，而是通过算法在连接正样本和一个K-最近邻的线段上的某个随机点产生一个新的正样本，新的样本可以向外拓展正类的决策边界。

## reference

数据挖掘导论

<https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28>

The Relationship Between Precision-Recall and ROC Curves 

An introduction to ROC analysis 